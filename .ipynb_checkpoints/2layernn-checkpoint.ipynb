{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Brandon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-06eba6f9b570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[0msizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m     \u001b[0mnnclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNerualNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[temprelu+softmax]Adam0.001\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[0mnnclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/train.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data/test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mnnclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitcombinedplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-06eba6f9b570>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, hidden_layer, regularization)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-06eba6f9b570>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         self.model = Sequential([\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_dimension\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class AccuracyHistory(Callback):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.acc = []\n",
    "        self.test = []\n",
    "\n",
    "    def on_epoch_end(self,batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.test.append(self.model.evaluate(self.data, self.label)[1])\n",
    "\n",
    "class NerualNetwork():\n",
    "    def __init__(self, name = \"temp\", hidden_layer = 10, regularization = 0.0):\n",
    "        self.name = name\n",
    "        self.input_dimension = 784\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.regularization = regularization\n",
    "        self.output_dimension = 10\n",
    "        self.model = None\n",
    "        self.opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    \n",
    "        self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.model = Sequential([\n",
    "            Dense(self.hidden_layer[0], input_dim = self.input_dimension, activation = 'relu', kernel_regularizer = l2(self.regularization)),\n",
    "            Dense(self.hidden_layer[1], activation = 'relu'), \n",
    "            Dense(self.output_dimension, activation = 'softmax')\n",
    "        ])\n",
    "        self.model.compile(optimizer = 'adam', loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    def load_data(self, train, test):\n",
    "        self.trainData = []\n",
    "        self.trainLabel = []\n",
    "        self.testData = []\n",
    "        self.testLabel = []\n",
    "        with open(train, 'r') as f:\n",
    "            print(\"Loading {}\".format(train))\n",
    "            header = True;\n",
    "            data = []\n",
    "            label = []\n",
    "            for line in f:\n",
    "                if (header):\n",
    "                    header = False\n",
    "                    continue\n",
    "                image = line.split(',')\n",
    "                data.append(list(map(int,image[1:])))\n",
    "                #lab = [0 for i in range(10)]\n",
    "                #lab[int(image[0])] = 1\n",
    "                label.append(image[0])\n",
    "            self.trainData = np.array(data) / 255\n",
    "            self.trainLabel = np.array(label)\n",
    "        with open(test, 'r') as f:\n",
    "            print(\"Loading {}\".format(test))\n",
    "            header = True;\n",
    "            data = []\n",
    "            label = []\n",
    "            for line in f:\n",
    "                if (header):\n",
    "                    header = False\n",
    "                    continue\n",
    "                image = line.split(',')\n",
    "                data.append(list(map(int, image[1:])))\n",
    "                #lab = [0 for i in range(10)]\n",
    "                #lab[int(image[0])] = 1\n",
    "                label.append(image[0])\n",
    "            self.testData = np.array(data) / 255\n",
    "            self.testLabel = np.array(label)\n",
    "        print(\"Done Loading Data\")\n",
    "\n",
    "    def train(self, epochs = 100, batch_size = 32):\n",
    "        print(\"Begin Training\")\n",
    "        history = AccuracyHistory(self.testData, self.testLabel)\n",
    "        self.model.fit(self.trainData, self.trainLabel, epochs = epochs, batch_size = batch_size, callbacks=[history])\n",
    "        self.plot(history.acc, history.test)\n",
    "\n",
    "    def plot(self, acc, score):\n",
    "        print(\"Training model with {0} hidden layers\".format(self.hidden_layer))\n",
    "        plt.figure()\n",
    "        plt.plot(range(len(acc)), acc, label=\"Training Score\")\n",
    "        plt.plot(range(len(score)), score, label = \"Test Score\")\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title('Classifier')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"model/\" + self.name + \".png\")\n",
    "        plt.figure(\"combined\")\n",
    "        plt.plot(range(len(acc)), acc, label = str(self.hidden_layer) + \"train\")\n",
    "        plt.plot(range(len(acc)), score, label = str(self.hidden_layer) + \"score\")\n",
    "\n",
    "    def initcombinedplot(self):\n",
    "        plt.figure(\"combined\")\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Classifier')\n",
    "        plt.grid(True)\n",
    "\n",
    "    def savecombinedplot(self):\n",
    "        plt.figure(\"combined\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"model/combined.png\")\n",
    "        \n",
    "\"\"\"\n",
    "    def load_data(self, train, test):\n",
    "        self.load(train[0], self.input_dimension, self.trainData)\n",
    "        self.load(train[1], 1, self.trainLabel)\n",
    "        self.load(test[0], self.input_dimension, self.testData)\n",
    "        self.load(test[1], 1, self.testLabel)\n",
    "\n",
    "    def load(self, fileName, dataSize, saveTo):\n",
    "        with open(\"data/\" + fileName, 'rb') as f:\n",
    "            data = []\n",
    "            while True:\n",
    "                sample = f.read(dataSize)\n",
    "                if len(sample) == 0:\n",
    "                    break\n",
    "                data.append([b for b in sample])\n",
    "        saveTo = np.array(data)\n",
    "        print(saveTo.shape)\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    sizes = [[5,5], 10, 25, 50, 100, 200]\n",
    "    nnclassifier = NerualNetwork(\"[temprelu+softmax]Adam0.001\", [10,10])\n",
    "    nnclassifier.load_data(\"data/train.csv\", \"data/test.csv\")\n",
    "    nnclassifier.initcombinedplot()\n",
    "    for i in sizes:\n",
    "        nnclassifier.__init__(\"[\" + str(i) + \"relu+softmax]Adam0.001\", i)\n",
    "        #nnclassifier.load_data((\"trainimages\", \"trainlabels\"), (\"testimages\", \"testlabels\"))\n",
    "        nnclassifier.train(epochs=10, batch_size=100)\n",
    "    nnclassifier.savecombinedplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
